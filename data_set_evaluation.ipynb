{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script corresponds to section 3.3 - Evaluation of data sets - of the paper \"Neural Media Bias Detection Using Distant Supervision With BABE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this script, you need the following files found in the /data directory:\n",
    "- \"raw_labels_MBIC.xlsx\"\n",
    "- \"raw_labels_SG1.xlsx\"\n",
    "- \"raw_labels_SG2.xlsx\"\n",
    "- \"final_labels_MBIC.xlsx\"\n",
    "- \"final_labels_SG1.xlsx\"\n",
    "- \"final_labels_SG2.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "import statsmodels\n",
    "from statsmodels.stats import inter_rater\n",
    "import krippendorff\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load raw labels of all subgroups containing all individual annotations for agreement calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"Your directory containing the data files\")\n",
    "MBIC_raw = pd.read_excel(\"raw_labels_MBIC.xlsx\")\n",
    "SG1_raw = pd.read_excel(\"raw_labels_SG1.xlsx\")\n",
    "SG2_raw = pd.read_excel(\"raw_labels_SG2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####preprocess labels --> encode string to int labels for agreement calculations\n",
    "MBIC_raw.replace(to_replace='Biased',value=1,inplace=True)\n",
    "MBIC_raw.replace(to_replace='Non-biased',value=0,inplace=True)\n",
    "MBIC_raw.replace(to_replace='Expresses writer’s opinion',value=2,inplace=True)\n",
    "MBIC_raw.replace(to_replace='Somewhat factual but also opinionated',value=1,inplace=True)\n",
    "MBIC_raw.replace(to_replace='Entirely factual',value=0,inplace=True)\n",
    "\n",
    "SG1_raw.replace(to_replace=\"Expresses wleter´s opinion\",value=2,inplace=True)\n",
    "SG1_raw.replace(to_replace=\"Expresses writer’s opinion\",value=2,inplace=True)\n",
    "SG1_raw.replace(to_replace='Somewhat factional but also opinionated',value=1,inplace=True)\n",
    "SG1_raw.replace(to_replace='Entirely factual',value=0,inplace=True)\n",
    "\n",
    "SG2_raw.replace(to_replace='Expresses writer’s opinion',value=2,inplace=True)\n",
    "SG2_raw.replace(to_replace='Somewhat factual but also opinionated',value=1,inplace=True)\n",
    "SG2_raw.replace(to_replace='Entirely factual',value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define pivot tables for bias agreement calculations\n",
    "MBIC_bias = MBIC_raw.pivot(index='survey_record_id', columns='text', values='label_bias')\n",
    "SG1_bias = SG1_raw.pivot(index='annotator_id', columns='text', values='Label_bias_0-1')\n",
    "SG2_bias = SG2_raw.pivot(index='df_id', columns='text', values='Label_bias_0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's alpha for bias labels in MBIC = 0.21\n",
      "Krippendorff's alpha for bias labels in SG1 = 0.39\n",
      "Krippendorff's alpha for bias labels in SG2 = 0.4\n"
     ]
    }
   ],
   "source": [
    "#calculate bias agreement\n",
    "bias_alpha_MBIC = krippendorff.alpha(MBIC_bias)\n",
    "print(\"Krippendorff's alpha for bias labels in MBIC = {}\".format(round(bias_alpha_MBIC,2)))\n",
    "bias_alpha_SG1 = krippendorff.alpha(SG1_bias)\n",
    "print(\"Krippendorff's alpha for bias labels in SG1 = {}\".format(round(bias_alpha_SG1,2)))\n",
    "bias_alpha_SG2 = krippendorff.alpha(SG2_bias)\n",
    "print(\"Krippendorff's alpha for bias labels in SG2 = {}\".format(round(bias_alpha_SG2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opinion agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivoting for opinion agreement calculation\n",
    "MBIC_opin = MBIC_raw.pivot(index='survey_record_id', columns='text', values='label_opinion')\n",
    "SG1_opin = SG1_raw.pivot(index='annotator_id', columns='text', values='label_opinion')\n",
    "SG2_opin = SG2_raw.pivot(index = 'df_id', columns='text', values='label_opinion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's alpha for opinion labels in MBIC = 0.26\n",
      "Krippendorff's alpha for opinion labels in SG1 = 0.46\n",
      "Krippendorff's alpha for opinion labels in SG2 = 0.6\n"
     ]
    }
   ],
   "source": [
    "#calculate opinion agreement\n",
    "opin_alpha_MBIC = krippendorff.alpha(MBIC_opin)\n",
    "print(\"Krippendorff's alpha for opinion labels in MBIC = {}\".format(round(opin_alpha_MBIC,2)))\n",
    "opin_alpha_SG1 = krippendorff.alpha(SG1_opin)\n",
    "print(\"Krippendorff's alpha for opinion labels in SG1 = {}\".format(round(opin_alpha_SG1,2)))\n",
    "opin_alpha_SG2 = krippendorff.alpha(SG2_opin)\n",
    "print(\"Krippendorff's alpha for opinion labels in SG2 = {}\".format(round(opin_alpha_SG2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load aggregated labels of all subgroups for calculation of descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:296: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "MBIC  = pd.read_excel(\"final_labels_MBIC.xlsx\")\n",
    "SG1 =  pd.read_excel(\"final_labels_SG1.xlsx\")\n",
    "SG2 = pd.read_excel(\"final_labels_SG2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Biased words per biased sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBIC: Average number of biased words in the biased sentences: 2.4\n",
      "SG1: Average number of biased words in the biased sentences: 1.95\n",
      "SG2: Average number of biased words in the biased sentences: 2.11\n"
     ]
    }
   ],
   "source": [
    "#MBIC\n",
    "MBIC[\"biased_words\"] = MBIC.biased_words.apply(lambda s: list(ast.literal_eval(s)))\n",
    "MBIC['num_biased_words'] = MBIC.biased_words.apply(lambda row: len(row))\n",
    "sent_with_biased_words = MBIC[MBIC['num_biased_words']>0]\n",
    "print('MBIC: Average number of biased words in the biased sentences:', round(sent_with_biased_words.num_biased_words.mean(),2))\n",
    "\n",
    "#SG1\n",
    "SG1[\"biased_words\"] = SG1.biased_words.apply(lambda s: list(ast.literal_eval(s)))\n",
    "SG1['num_biased_words'] = SG1.biased_words.apply(lambda row: len(row))\n",
    "sent_with_biased_words = SG1[SG1['num_biased_words']>0]\n",
    "print('SG1: Average number of biased words in the biased sentences:', round(sent_with_biased_words.num_biased_words.mean(),2))\n",
    "\n",
    "#SG2\n",
    "SG2[\"biased_words\"] = SG2.biased_words.apply(lambda s: list(ast.literal_eval(s)))\n",
    "SG2['num_biased_words'] = SG2.biased_words.apply(lambda row: len(row))\n",
    "sent_with_biased_words = SG2[SG2['num_biased_words']>0]\n",
    "print('SG2: Average number of biased words in the biased sentences:', round(sent_with_biased_words.num_biased_words.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Total biased words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count total numbers of words\n",
    "sum_words_SG1 = 0 #MBIC and SG1 have the same number of biased words since they comprise identical sentences\n",
    "sum_words_SG2 = 0\n",
    "\n",
    "for sent in SG1['text']:\n",
    "    sum_words_SG1 += len(sent.split())\n",
    "for sent in SG2['text']:\n",
    "    sum_words_SG2 += len(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3283 out of 56826 words are labeled as biased in MBIC\n",
      "1530 out of 56826 words are labeled as biased in SG1\n",
      "3902 out of 116232 words are labeled as biased in SG2\n"
     ]
    }
   ],
   "source": [
    "#MBIC\n",
    "biased_words_sum_MBIC = MBIC['num_biased_words'].sum()\n",
    "print (\"{} out of {} words are labeled as biased in MBIC\".format(biased_words_sum_MBIC,sum_words_SG1))\n",
    "\n",
    "#SG1\n",
    "biased_words_sum_SG1 = SG1['num_biased_words'].sum()\n",
    "print (\"{} out of {} words are labeled as biased in SG1\".format(biased_words_sum_SG1,sum_words_SG1))\n",
    "\n",
    "#SG2\n",
    "biased_words_sum_SG2 = SG2['num_biased_words'].sum()\n",
    "print (\"{} out of {} words are labeled as biased in SG2\".format(biased_words_sum_SG2,sum_words_SG2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBIC Bias Label Distribution \n",
      "      label_bias  num_sentences  percentage \n",
      "0        Biased           1018    59.882353\n",
      "1    Non-biased            533    31.352941\n",
      "2  No agreement            149     8.764706\n",
      "---------------------------------\n",
      "SG1 Bias Label Distribution \n",
      "      label_bias  num_sentences  percentage \n",
      "0        Biased            746    43.882353\n",
      "1    Non-biased            800    47.058824\n",
      "2  No agreement            154     9.058824\n",
      "---------------------------------\n",
      "SG2 Bias Label Distribution \n",
      "      label_bias  num_sentences  percentage \n",
      "0        Biased           1810    49.265106\n",
      "1    Non-biased           1863    50.707676\n",
      "2  No agreement              1     0.027218\n"
     ]
    }
   ],
   "source": [
    "#MBIC\n",
    "bias_obs_MBIC = MBIC.groupby(['label_bias'])[['text']].count()\n",
    "bias_obs_MBIC = bias_obs_MBIC.reset_index()\n",
    "bias_obs_MBIC = bias_obs_MBIC.rename(columns={\"text\": \"num_sentences\"})\n",
    "bias_obs_MBIC['sorting'] = [1, 3, 2]\n",
    "bias_obs_MBIC = bias_obs_MBIC.sort_values(by=['sorting']).reset_index()\n",
    "bias_obs_MBIC = bias_obs_MBIC[['label_bias','num_sentences']]\n",
    "bias_obs_MBIC['percentage '] = bias_obs_MBIC['num_sentences'] / bias_obs_MBIC['num_sentences'].sum() * 100 # get percentage\n",
    "\n",
    "#SG1\n",
    "bias_obs_SG1 = SG1.groupby(['label_bias'])[['text']].count()\n",
    "bias_obs_SG1 = bias_obs_SG1.reset_index()\n",
    "bias_obs_SG1 = bias_obs_SG1.rename(columns={\"text\": \"num_sentences\"})\n",
    "bias_obs_SG1['sorting'] = [1, 3, 2]\n",
    "bias_obs_SG1 = bias_obs_SG1.sort_values(by=['sorting']).reset_index()\n",
    "bias_obs_SG1 = bias_obs_SG1[['label_bias','num_sentences']]\n",
    "bias_obs_SG1['percentage '] = bias_obs_SG1['num_sentences'] / bias_obs_SG1['num_sentences'].sum() * 100 #get percentage\n",
    "\n",
    "#SG2\n",
    "bias_obs_SG2 = SG2.groupby(['label_bias'])[['text']].count()\n",
    "bias_obs_SG2 = bias_obs_SG2.reset_index()\n",
    "bias_obs_SG2 = bias_obs_SG2.rename(columns={\"text\": \"num_sentences\"})\n",
    "bias_obs_SG2['sorting'] = [1, 3, 2]\n",
    "bias_obs_SG2 = bias_obs_SG2.sort_values(by=['sorting']).reset_index()\n",
    "bias_obs_SG2 = bias_obs_SG2[['label_bias','num_sentences']]\n",
    "bias_obs_SG2['percentage '] = bias_obs_SG2['num_sentences'] / bias_obs_SG2['num_sentences'].sum() * 100 #get percentage\n",
    "\n",
    "print(\"MBIC Bias Label Distribution\",\"\\n\",bias_obs_MBIC)\n",
    "print(\"---------------------------------\")\n",
    "print(\"SG1 Bias Label Distribution\",\"\\n\",bias_obs_SG1)\n",
    "print(\"---------------------------------\")\n",
    "print(\"SG2 Bias Label Distribution\",\"\\n\",bias_obs_SG2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opinion Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBIC Opinion Label Distribution \n",
      "   label_opinion  num_sentences  percentage \n",
      "0   Opinionated            521    30.647059\n",
      "1       Factual            572    33.647059\n",
      "2          Both            433    25.470588\n",
      "3  No agreement            174    10.235294\n",
      "---------------------------------\n",
      "SG1 Opinion Label Distribution \n",
      "   label_opinion  num_sentences  percentage \n",
      "0   Opinionated            425    25.000000\n",
      "1       Factual            639    37.588235\n",
      "2          Both            453    26.647059\n",
      "3  No agreement            183    10.764706\n",
      "---------------------------------\n",
      "SG2 Opinion Label Distribution \n",
      "   label_opinion  num_sentences  percentage \n",
      "0   Opinionated            858    23.353293\n",
      "1       Factual           1600    43.549265\n",
      "2          Both           1000    27.218291\n",
      "3  No agreement            216     5.879151\n"
     ]
    }
   ],
   "source": [
    "#MBIC\n",
    "opin_obs_MBIC = MBIC.groupby(['label_opinion'])[['text']].count()\n",
    "opin_obs_MBIC = opin_obs_MBIC.reset_index()\n",
    "opin_obs_MBIC = opin_obs_MBIC.rename(columns={\"text\": \"num_sentences\"})\n",
    "opin_obs_MBIC['sorting'] = [2, 1, 4,3]\n",
    "opin_obs_MBIC = opin_obs_MBIC.sort_values(by=['sorting']).reset_index()\n",
    "opin_obs_MBIC = opin_obs_MBIC[['label_opinion','num_sentences']]\n",
    "opin_obs_MBIC = opin_obs_MBIC.replace('Entirely factual', 'Factual')\n",
    "opin_obs_MBIC = opin_obs_MBIC.replace('Expresses writer’s opinion', 'Opinionated')\n",
    "opin_obs_MBIC = opin_obs_MBIC.replace('Somewhat factual but also opinionated', 'Both')\n",
    "opin_obs_MBIC['percentage '] = opin_obs_MBIC['num_sentences'] / opin_obs_MBIC['num_sentences'].sum() * 100 # get percentage\n",
    "\n",
    "#SG1\n",
    "opin_obs_SG1 = SG1.groupby(['label_opinion'])[['text']].count()\n",
    "opin_obs_SG1 = opin_obs_SG1.reset_index()\n",
    "opin_obs_SG1 = opin_obs_SG1.rename(columns={\"text\": \"num_sentences\"})\n",
    "opin_obs_SG1['sorting'] = [2, 1, 4,3]\n",
    "opin_obs_SG1 = opin_obs_SG1.sort_values(by=['sorting']).reset_index()\n",
    "opin_obs_SG1 = opin_obs_SG1[['label_opinion','num_sentences']]\n",
    "opin_obs_SG1 = opin_obs_SG1.replace('Entirely factual', 'Factual')\n",
    "opin_obs_SG1 = opin_obs_SG1.replace('Expresses writer’s opinion', 'Opinionated')\n",
    "opin_obs_SG1 = opin_obs_SG1.replace('Somewhat factual but also opinionated', 'Both')\n",
    "opin_obs_SG1['percentage '] = opin_obs_SG1['num_sentences'] / opin_obs_SG1['num_sentences'].sum() * 100 # get percentage\n",
    "\n",
    "#SG2\n",
    "opin_obs_SG2 = SG2.groupby(['label_opinion'])[['text']].count()\n",
    "opin_obs_SG2 = opin_obs_SG2.reset_index()\n",
    "opin_obs_SG2 = opin_obs_SG2.rename(columns={\"text\": \"num_sentences\"})\n",
    "opin_obs_SG2['sorting'] = [2,1, 4,3]\n",
    "opin_obs_SG2 = opin_obs_SG2.sort_values(by=['sorting']).reset_index()\n",
    "opin_obs_SG2 = opin_obs_SG2[['label_opinion','num_sentences']]\n",
    "opin_obs_SG2 = opin_obs_SG2.replace('Entirely factual', 'Factual')\n",
    "opin_obs_SG2 = opin_obs_SG2.replace('Expresses writer’s opinion', 'Opinionated')\n",
    "opin_obs_SG2 = opin_obs_SG2.replace('Somewhat factual but also opinionated', 'Both')\n",
    "opin_obs_SG2['percentage '] = opin_obs_SG2['num_sentences'] / opin_obs_SG2['num_sentences'].sum() * 100 # get percentage\n",
    "\n",
    "print(\"MBIC Opinion Label Distribution\",\"\\n\",opin_obs_MBIC)\n",
    "print(\"---------------------------------\")\n",
    "print(\"SG1 Opinion Label Distribution\",\"\\n\",opin_obs_SG1)\n",
    "print(\"---------------------------------\")\n",
    "print(\"SG2 Opinion Label Distribution\",\"\\n\",opin_obs_SG2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
